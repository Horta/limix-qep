Title         : QEP
Author        : Danilo Horta
Affiliation   : EMBL-EBI
Email         : horta@ebi.ac.uk

Bib style     : plainnat
Bibliography  : example
Logo          : True

Doc class     : [10pt]article

[TITLE]

> Life swings like a pendulum backward and forward between pain and boredom.\
&emsp;&emsp; --- Arthur Schopenhauer


# Prior

~ MathDefs
\renewcommand{\t}{^{\intercal}}
\renewcommand{\i}{^{-1}}
\newcommand{\K}{\mathrm{K}}
\newcommand{\Q}{\mathrm{Q}}
\renewcommand{\S}{\mathrm{S}}
\newcommand{\BE}{\mathrm{B}}
\newcommand{\I}{\mathrm{I}}
\newcommand{\mm}{\boldsymbol{\mathrm m}}
\newcommand{\MM}{\mathrm{M}}
\newcommand{\bbeta}{\boldsymbol{\beta}}
\newcommand{\tT}{\tilde{\mathrm T}}
\newcommand{\teta}{\tilde{\boldsymbol\eta}}
\newcommand{\bmu}{\boldsymbol{\mu}}
\newcommand{\Sig}{\Sigma}
\newcommand{\A}[1]{\mathrm{A_{#1}}}
\renewcommand{\k}{\mathrm{k}}
\newcommand{\bk}{\boldsymbol{\mathrm{k}}}
\newcommand{\tmu}{\tilde{\mu}}
\newcommand{\tbmu}{\tilde{\bmu}}
\newcommand{\tsig}{\tilde{\sigma}}
\newcommand{\sig}{\sigma}
\newcommand{\half}{\frac{1}{2}}
~


~ Equation
\begin{aligned}
    \K &= v \Q \S \Q\t + v \delta \I       \\
    \mm &= \MM \bbeta
\end{aligned}
~

# Posterior

~ Equation
\begin{aligned}
  \Sig &= (\K\i + \tT)\i                  \\
  \bmu &= \Sig (\K\i \mm + \teta)
\end{aligned}
~


# Aux

## Handy matrices

~ Equation
\begin{aligned}
  \A{0} &= v \delta \I                                         \\
  \A{1} &= (v \delta \I + \tT\i)\i = \tT (v \delta \tT + \I)\i \\
  \A{2} &= \tT\i \A{1} = (v \delta \tT + \I)\i                 \\
  \BE    &= \Q\t \A{1} \Q + (v \S)\i
\end{aligned}
~

## Handy formula
~ Equation
\begin{aligned}
  (\K\i + \tT)\i &= \tT\i (\K + \tT\i)\i \K                 \\
  (\K + \tT\i)\i  &= \A{1} - \A{1} \Q\BE\i \Q\t \A{1}
\end{aligned}
~

~ Note
Pre-compute $\Q \BE\i \Q\t$ and $\K$ when there is no rank deficiency in $\K$.
~

# Posterior implementation

~ Equation
\begin{aligned}
  \Sigma &= \tT\i (\tT\i + \K)\i \K = \tT\i (\A{1} - \A{1} \Q \BE\i\Q\t \A{1}) \K                         \\
         &= \A{2} \K - \A{2} \Q \BE\i\Q\t \A{1} \K   \\
  \bmu   &= \tT\i (\tT\i + \K)\i \mm + \tT\i (\tT\i + \K)\i \K \teta\\
         &= \tT\i (\A{1} - \A{1} \Q \BE\i\Q\t \A{1}) \mm + \tT\i (\A{1} - \A{1} \Q \BE\i\Q\t \A{1}) \K \teta\\
         &= \A{2} \mm - \A{2} \Q \BE\i\Q\t \A{1} \mm + \A{2} \K \teta - \A{2} \Q \BE\i\Q\t \A{1} \K \teta
\end{aligned}
~

# Prediction

~ Equation
\begin{aligned}
\mu_*      &= m_* - \bk_{*}\t \K\i \bmu \\
\sig^2_*   &= \k_{*,*} - \bk_{*}\t (\A{1} - \A{1} \Q \BE\i \Q\t \A{1}) \bk_{*}
\end{aligned}
~

~ Note
Use $\K\i = v\i\Q (\S + \delta \I)\i \Q\t$ decomposition to compute $\K\i\bmu$.
~


# Log marginal likelihood

~ Equation
\begin{aligned}
  \text{LML} &= - \half \log |\K + \tT\i| - \half (\mm - \tbmu)^{T} (\K + \tT\i)\i (\mm - \tbmu)                               \\
             &+ \sum_i \log \Phi\left( \frac{y_i \mu_{-i}}{\sqrt{1 + \sig_{-i}^2}} \right)                                 \\
             &+ \half \sum_i \log(\tsig_i^2 + \sig_{-i}^2) + \sum_i \frac{(\tmu_i - \mu_{-i})^2}{2 (\tsig_i^2 + \sig_{-i}^2)}
\end{aligned}
~

#### Part 1

~ Equation
-\half\log \big|\K + \tT\i\big| = -\half\log\big|\BE\big| -\half \log\big|v \S\big| +\half\log\big|\A{1}\big|
~

#### Part 2

~ Equation
\begin{aligned}
\sum_i \frac{(\tmu_i - \mu_{-i})^2}{2 (\sig_i^2 + \sig_{-i}^2)} &= \frac{\tbmu\t (\tT\i + \Sig_-)\i \tbmu}{2} -
                                                                   \tbmu\t (\tT\i + \Sig_-)\i \bmu_- \\
                                                                &+ \frac{\bmu_{-}\t (\tT\i + \Sig_-)\i\bmu_-}{2}
\end{aligned}
~

#### Part 3

~ Equation
\begin{aligned}
        &~~~- \frac{\tbmu\t (\K + \tT\i)\i \tbmu}{2} + \frac{\tbmu^{T} (\tT\i + \Sig_-)\i \tbmu}{2} =                           \\
        &= \half \teta\t \Big( -\tT\i\A{1}\tT\i + \tT\i \A{1} \Q\BE\i \Q\t \A{1}\tT\i + \tT\i - (\tT + \Sig_-\i)\i \\Big) \teta\\
        &= \half \teta (\A{0} (\tT \A{0} + \mathrm I)\i + \A{2} \Q\BE\i\Q\t \A{2} - (\tT + \Sig_-\i)\i ) \teta
\end{aligned}
~

#### Part 4

~ Equation
\half\bmu_-\t (\tT\i + \Sig_-)\i (\bmu_- - 2 \tbmu) = \half \teta_-\t (\tT + \Sig_-\i)\i (\tT \bmu_- - 2 \teta)
~

#### Part 5

~ Equation
\mm\t(\K + \tT\i)\i \tbmu = \mm\t \A{2} \teta - \mm\t \A{1} \Q \BE\i \Q\t \A{2} \teta
~

#### Part 6

~ Equation
\begin{aligned}
  - \half \mm\t (\K + \tT\i)\i \mm = - \half \mm\t \A{1} \mm + \half \mm\t \A{1} \Q \BE\i \Q\t \A{1} \mm
\end{aligned}
~


#### Part 7

~ Equation
\half \sum_i \log(\sig_i^2 + \sig_{-i}^2) = \half \big(-\log|\tT| + \log|\tT + \Sig_-\i| - \log|\Sig_-\i|\big)
~

> Note that from Part 1 and Part 7 we have $\half \log |\A{1}|$ and
> $-\half \log |\tT|$, respectively.
> Their sum is given by $\half \log |\A{2}|$ and is defined therefore
> as Part 9.

# Optimal beta

Let $\mm = \MM \bbeta$ be the mean and $\K$ be the
covariance. The optimal $\bbeta^*$ is given by
taking the gradient of LML and setting it to zero.


~ Equation
\begin{aligned}
\bbeta^* = (\MM\t (\tT\i + \K)\i \MM)\i \MM\t (\tT\i + \K)\i \tbmu.
\end{aligned}
~

## Implementation

~ Equation
\begin{aligned}
  \bbeta^* &= (\MM\t \A{1} \MM - \MM\t \A{1} \Q \BE\i \Q\t \A{1} \MM)\i (\MM\t \A{1} - \MM\t\A{1} \Q \BE\i \Q\t \A{1}) \tbmu  \\
           &= (\MM\t \A{1} \MM - \MM\t \A{1} \Q \BE\i \Q\t \A{1} \MM)\i \MM\t (\A{2} - \A{1} \Q \BE_1\i \Q\t\A{2}) \teta
\end{aligned}
~

<!--
# Derivative over variance (it needs a review)

\[
  \frac{\partial \text{LML}}{\partial \theta} =
    \frac{1}{2} (\mathbf m - \tilde{\boldsymbol{\mu}})^{\mathrm T}
    (\mathrm K + \tilde \Sigma)^{-1} \frac{\partial \mathrm K}{\partial \theta}
    (\mathrm K + \tilde \Sigma)^{-1} (\mathbf m - \tilde{\boldsymbol{\mu}})\\
    - (\mathbf m - \tilde{\boldsymbol{\mu}})^{\mathrm T} (\mathrm K +
        \tilde{\mathrm T}^{-1})^{-1}
    \frac{\partial \mathbf m}{\partial \theta} - \frac{1}{2} \text{tr}\Big(
      (\mathrm K + \tilde{\mathrm T}^{-1})^{-1}
      \frac{\partial \mathrm K}{\partial \theta}\Big)
\]

Part 1

\[
  (\mathrm K+\tilde{\mathrm T}^{-1})^{-1} \tilde{\boldsymbol \mu} =
    \mathrm A_0(\mathrm A_0 + \tilde{\mathrm T})^{-1}
    \tilde{\boldsymbol\eta} - \mathrm A_1 \mathrm Q \mathrm B^{-1}
    \mathrm Q^{\mathrm T} \mathrm A_0 (\mathrm A_0 + \tilde{\mathrm T})^{-1}
    \tilde{\boldsymbol \eta}
\]

Part 2

\[
  (\mathrm K+\tilde{\mathrm T}^{-1})^{-1} \mathbf m =
    \mathrm A_1 \mathbf m
    - \mathrm A_1 \mathrm Q \mathrm B^{-1}
    \mathrm Q^{\mathrm T} \mathrm A_1 \mathbf m
\]

Part 3

\[
  \text{tr}[(\mathrm K + \tilde{\mathrm T}^{-1})^{-1}] = \text{tr}[\mathrm A_1
    \frac{\partial \mathrm K}{\partial \theta}] -
    \text{tr}[\mathrm A_1 \mathrm Q \mathrm B^{-1} \mathrm Q^{\mathrm T}
    \mathrm A_1
    \frac{\partial \mathrm K}{\partial \theta}]
\]
-->
